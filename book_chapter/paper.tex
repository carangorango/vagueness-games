\documentclass[a4paper]{article}

\usepackage[natbib=true,style=authoryear-comp,backend=biber,doi=false,url=false,isbn=false]{biblatex}
\bibliography{paper}

\usepackage{todonotes}
\usepackage{a4wide}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{syllogism}
\usepackage{subcaption}


\begin{document}

\title{Natural sources of vagueness and their implications}
\author{Michael Franke \and Jos\'e Pedro Correia}
\date{}

\maketitle

\begin{abstract}
A vexing puzzle about vagueness, rationality and evolution runs, in crude abbreviation, as follows: vague language use is demonstrably suboptimal if the goal is efficient precise and cooperative information transmission; hence rational deliberation or evolutionary selection should, under this assumed goal, eradicate vagueness from language use.
Since vagueness is persistent in all human languages, something has to give.
In this paper, we investigate a number of reasons why and mechanisms how vagueness may come into the picture in formal models of rational or evolutionary optimal signaling.
We show how uncertainty about not only the linguistic practices of others, but also about the world itself can lead to vagueness, and how, given vagueness, natural linguistic practices are likely to create more reason for vagueness.
We explore the consequences of these reasons and mechanism for a notion of meaning and a notion of language.
\end{abstract}

\tableofcontents

\section{Vagueness}
\label{sec:vagueness}

The classical philosophical problem of vagueness is most starkly embodied by the sorites paradox.
The original formulation is attributed to Eubulides, an ancient Megarian philosopher~\parencite{sorensen_sorites_2009}, and uses the example of a heap of sand: if $1 000 000$ grains of sand piled up together clearly form a heap, and removing one grain of sand can never make a heap into a non-heap, then if we remove one grain, the remaining $999 999$ also clearly form a heap; by repeated applications of this reasoning we can remove almost all grains of sand one by one and are lead to acknowledge that $1$ single grain of sand also forms a heap.
This paradox is interesting because it can be made general and re-applied to many other words besides `heap'.
In the general formulation, we start with an $x$ to which a certain predicate $P$ clearly applies.
We observe that a certain transformation $f$ has no impact on whether something is or is not $P$.
Thus we are lead to acknowledge that the predicate $P$ also applies to $y = f(x)$.
Moreover, we can apply the same reasoning subsequently to $f(x)$ and repeat that as many times as the transformation is still applicable.
The paradox arises when $n$ repeated applications of the transformation $f$ lead us from $x$ to $z = f^n(x)$, where $z$ is something for which originally we would say $P$ clearly does not apply, but since we see it as difficult to reject either the premisses or the reasoning, we seem to be forced to accept that $P$ \emph{does in fact apply} to $x$.
The paradox with the heap can thus be seen as an instance of this general formulation, if $x$ is the group of $1 000 000$ grains of sand, the transformation is removing a grain, and $z$ the state of one (or even zero) grains.
It can also be reversed: it seems reasonable to accept that piling up a grain of sand to something that is not a heap will not turn it into a heap of sand, thus 
by repeated applications of that transformation one can pile up as many grains of sand as one likes and will never obtain a heap.

Predicates for which one can find a suitable instance of the general formulation of the sorites paradox are called \emph{vague}.
Paradigmatic examples besides `heap' include `tall', `red', `bald', `tadpole', and `child'~\parencite{Keefe1997}.
An important intuition regarding these predicates that enables the sorites paradox to go through is that there does not seem to be any clear boundary demarcating the cases where the predicate applies from the cases where it doesn't, but there are nevertheless examples of both cases.
Intuitively, a person with a height of 2 meters is tall, and one with a height of 1.5 meters is not, but there is no value of height in between where one would draw the line; saying, for example, that a person with a height of 1.80 meters is tall, but a person measuring 1.79 meters is not, just seems preposterous.
Neither drawing a sharp boundary seems reasonable, nor do the logical consequences of not doing so, and in there lies the truely paradoxical issue of vagueness.
How widespread is the problem?
It is easy to come up with more examples of predicates that are based on more finely grained properties, like `tall' is intuitively based on height, for which constructing a sorites paradox would be easy.
Mereological nihilists argue that instances of the sorites can be designed for any material object that can be decomposed into small enough parts.
If we subscribe to the scientific picture of matter as composed of molecules and atoms, this applies to tables and chairs, cats and mats, and any other ordinary thing~\parencite{Unger1979}.
Any heap of molecules that we have a name for is potentially at the mercy of being hypotheticall chipped away into nothingness while still keeping its name.
The problem thus seems to be a serious one.
Bertrand Russell famously argued~\parencite*{russell_vagueness_1923} that all words, including ``the words of pure logic'', are vague when used by human beings.
In face of such a powerful paradox like the sorites, something has got to give.

Vagueness is typically seen as a challenge to a classical conception of language and meaning.
We can summarize this classical picture as such: words stand in a direct or mediated correspondence to their meanings; sentences are combinations of such words bound by logical rules; knowledge of the meanings of words and of how the rules combine them allows us to know the meaning of sentences and determine whether they are true or false.
With variations, this picture could be said to underlie theories of meaning of authors life Gottlob Frege, Bertrand Russell, Ludwig Wittgenstein (his early work), Alfred Tarski, Richard Montague, and many others, especially those working in the analytic tradition.
The problem is that vague predicates seem to lack precise boundaries; if that is the case, how can words like `tall' stand in correspondence to a well defined set of people?
And if we cannot know exactly whether a certain person is `tall' or not, as with borderline cases, how are we to determine the truth value of sentences that involve statements of tallness regarding this person?

Some argue that the problems caused by vagueness are not serious enough for us to throw away the picture of meaning outlined above.
Timothy Williamson, for example, claims that we should stick with the classical picture because ``[c]lassical logic and semantics are vastly superior to the alternatives in simplicity, power, past success, and integration with theories in other domains.''~\parencite*[162]{williamson_vagueness_1992}
In the face of vagueness, Williamson defends the so-called \emph{epistemic view}: vague terms do determine precise boundaries, we just don't have the ability to know where they are; there is a precise height above which people are tall, and below which they are not, we are just ignorant of what this value is.
%%% Could talk about Frazee, J., and Beaver, D. (2010) here
The epistemic approach is curious in that, in its attempt to save truth, it seems to actually render it sterile as an explanatory notion.
If we can never ascertain truth when it comes to vague terms, how can truth be relevant for explaining how we understand or produce language?
If the concept of truth is crucially tied to meaning, but we have no access to the former, how could we ever have learned the latter?
Williamson's reason to ignore these problems is a pragmatic one: he believes it helps us, philosophers of language and theoretical linguists, to better understand natural language.
But this reason holds only insofar as we agree with this assessment of the success of the classical picture.

Criticism of the adequacy of this picture, however, comes from various quarters.
One of the strongest can be found in the later work of philosopher Ludwig Wittgenstein\footnote{To the extent that substantial views can be said to be defended by the author. Skipping over the debate (see \cite{kahane_wittgenstein_2007} for more details), we are here assuming an interpretation of Wittgenstein as a kind of pragmatist, along the lines of the readings of Hilary Putnam~\parencite*{putnam_pragmatism_1994} and Richard Rorty~\parencite*{rorty_wittgenstein_2007}.}, most importantly in the \emph{Philosophical Investigations}~\parencite*{wittgenstein_philosophical_1953}.
Undermining several assumptions behind the classical picture and the implications thereof, Wittgenstein pushes for a paradigm shift:
\begin{quote}
The more closely we examine actual language, the greater becomes the conflict between it and our requirement.
(For the crystalline purity of logic was, of course, not something I had \emph{discovered}: it was a requirement.)
The conflict becomes intolerable; the requirement is now in danger of becoming vacuous.
-- We have got on to slippery ice where there is no friction, and so, in a certain sense, the conditions are ideal; but also, just because of that, we are unable to walk.
We want to walk: so we need \emph{friction}.
Back to the rough ground!%
~\parencite[\S 107]{wittgenstein_philosophical_1953}
\end{quote}
He argues that the ideal of exactness that is tied to the notions of truth and logic dazzles and leads to misunderstandings~\parencite*[\S 100]{wittgenstein_philosophical_1953}; it creates a haze around the workings of language~\parencite*[\S 5]{wittgenstein_philosophical_1953} that keeps us from seeing what is right in front of us.
We can only escape this predicament, not by bargaining exactness out of logic, but by turning our whole inquiry around~\parencite*[\S 108]{wittgenstein_philosophical_1953}, \emph{i.e.}~by thinking of language in terms of a different paradigm.

%%% This discussion is perhaps too detailed for the scope of this paper
% Another suggested theory that attempts to retain as much as possible from classical logic by making minimal modifications to the classical picture of semantics is \emph{supervaluationism}.
% Championed by Kit Fine~\parencite*{Fine1975}, the idea is that vague predicates can be made precise, even arbitrarily.
% Setting a boundary between tall and not tall people at 1.80 meters would be an admissible%
% \footnote{Only precisifications that meet certain constraints should be considered. We refer the reader to Fine's article~\parencite*{Fine1975} for the details.}
% \emph{precisification} of the word `tall'.
% What supervaluationism defends is that, when considering the truth value of a sentence with vague terms, we should take all admissible precisifications of those terms into account: the sentence is true if true under all of them, false if false under all of them, and neither true nor false otherwise.
% The intuition is that a person with a height of 2 meters would be considered tall under all admissible precisifications, thus we could say it is true that that person is tall; for someone measuring 1.79 this would not be the case, hypothetically being true under some precisifications and false under others.
% %In defending this approach, supervaluationism either assumes or postulates the potential existence of a boundary between the sentences for which all admissible precisifications of the vague terms therein make them true, and those for which at least one precisification makes them false.
% Although supervaluationism claims to retain classical logics, it seems to implicitly require a third truth value to account for sentences for which not all precisifications are in agreement.
% Other responses to the problem of vagueness develop alternative logics that explicitly break away from the bivalent assumption that a sentence is either true or false, and introduce additional truth values.
% These range from three-valued logics~\parencite[\emph{e.g.}][]{tye_sorites_1994} to infinite-valued degree theories~\parencite[\emph{e.g.}][]{machina_truth_1976}.

The way in how the ideal of exactness leads into misunderstandings is somewhat patent in the standard approaches to dealing with vagueness that try to hang on to as much as possible of the classical picture.
Supervaluationism, many-valued logics, and degree theories all propose changes to it in order to accommodate for vague predicates.
The proposals are, however, still within the general molds of the classical picture.
Mark Sainsbury~\parencite*{sainsbury_concepts_1999} argues that, because of that, they all fail to address an important characteristic of vague predicates: \emph{higher order vagueness}.
All the aforementioned proposals end up being committed to new artificial demarcating boundaries (\emph{e.g.}~true-under-all-precisifications versus neither true nor false versus false-under-all-precisifications, true versus indefinite versus false, true to degree 1 versus true to degree 0 versus the rest).
But a vague predicate not only fails to demarcate between the cases where it clearly applies and the ones where it clearly doesn't, it also fails to establish a boundary between the cases where it clearly applies and the borderline cases, as well as between the borderline cases and the cases where it clearly doesn't apply.
Further introducing borderline borderline cases would lead into an infinite regress.
Because of their attachment to the classical picture, the standard approaches to vagueness fail to see an important lesson, namely that ``we do not know, cannot know, and do not need to know these supposed boundaries to use language correctly''~\parencite*[256]{sainsbury_concepts_1999}.
% \begin{quote}
% But to what in our actual use of language does this division correspond?
% It looks as if, as before, it should correspond to the sentences true beyond the shadow of vagueness, those in some kind of borderline position, and those false beyond the shadow.
% But [\ldots] we do not know, cannot know, and do not need to know these supposed boundaries to use language correctly.
% Hence they cannot be included in a correct description of our language.%
% ~\parencite[256]{sainsbury_concepts_1999}
% \end{quote}
By trying to cling as much as possible to the classical picture of logic and semantics, these standard approaches are ignoring a simple observation: natural language users are sensitive to the sorites paradox, \emph{i.e.}~are able to recognize the logical inconsistency but do not have a good answer to overcome it.
Even more importantly, they apparently do not need to solve the inconsistency in order to continue using natural language productively.
Nobody ever stopped using the word `tall` after being confronted with a sorites series to deconstruct it.
Why should we develop theories of meaning that are impervious to the paradox?

The reluctance to give up truth and logic as valuable notions to explain meaning is perhaps associated with the fear of what would also consequently need to be abandoned down the line.
Talking about philosophers who defend the desirability of a classical notion of truth, Richard Rorty says:
\begin{quote}
In the past, such philosophers have typically conjoined the claim that there is universal human agreement on the supreme desirability of truth with two further premises: that truth is correspondence to reality, and that reality has an intrinsic nature (that there is, in Nelson Goodman's terms, a Way the World Is).
[\ldots]
The rise of relatively democratic, relatively tolerant, societies in the last few hundred years is said to be due to the increased rationality of modern times, where `rationality' denotes the employment of an innate truth-oriented faculty.%
~\parencite*[1]{rorty_response_2000-1}
\end{quote}
Rationality, in this picture, has truth as its guiding light and logic as the means to attain it.
The fear could be that, if we drop the picture of meaning as intimately tied to truth and logic, we lose the ground on which rationality stands, and the whole edifice would collapse.
But giving up the ideal of truth and logic as relevant explanatory notions to understand natural language does not mean giving up on rationality, or any of the other notions, altogether.
To say that language does not follow strict logical rules, or that truth is not a useful notion to guide our inquiries into meaning, is not to say that language is unstructured, meaningless, or unusable; neither is it to say that we, language users, are therefore completely irrational.
Vagueness can shed light on features of our language and our rationality, but only after we step out of the classical picture and start looking at these concepts in terms of a different paradigm.

What can such a paradigm be?
The Wittgensteinian picture of language is one of multiplicity, heterogeneity, and change.
Languages are thought of as patchworks of various language-games, with new ones continuously being added and old ones falling out of use.
These language-games, in turn, are situated uses of words in certain activities.
The metaphor emphasizes a concept of meaning as strongly linked to the use that words or signs are put to.
Meaning is thus contingent to the language-games we play, and dynamic.
The notion of language-game is also used to characterize one of Wittgenstein's methodological tools.
Following the idea that ``[i]t disperses the fog if we study the phenomena of language in primitive kinds of use in which one can clearly survey the purpose and functioning of the words''~\parencite*[\S 5]{wittgenstein_philosophical_1953}, the method is to set up such a language-game as a hypothetical scenario, or thought experiment, where language is used in a certain type of activity, and then reflect on the assumptions that underlie our interpretation of this set-up, as well as on how the scenario would play through according to those assumptions.
Jos\'e Pedro Correia~\parencite*{correia_bivalent_2013} argues that the framework of signaling games, introduced for the study of meaning by David Lewis~\parencite*{lewis_convention_1969} and later naturalized by Brian Skyrms~\parencite*{skyrms_evolution_1996,skyrms_signals_2010}, permits us to do exactly that, while reaping the benefits of a mathematical formalism and the further ability to conduct computer simulations.
From this perspective, creating a signaling game model is like setting up a language-game, only using a formulation that improves perspicuity, and conducting computer simulations is like contemplating how the game would play through according to the implications of the assumptions one built into the model.

In the following, we will be looking at signaling models of vagueness in order to provide an overview of proposals of natural sources of vagueness, what that tells us about rationality, and the implications of these ideas.
But first, let us look in more detail into how Lewis-Skyrms signaling games work, and how vagueness shows up again as a different kind of problem for these models.
%With regards to vagueness and exactness, it is also important to note the following:
%\begin{quote}
%``Inexact'' is really a reproach, and ``exact'' is praise.
%And that is to say that what is inexact attains its goal less perfectly than does what is more exact.
%So it all depends on what we call ``the goal''.
%\end{quote}

%%% This is perhaps too philosophical and off-topic
% The reluctance to give up truth and logic as fundamental concepts to understand meaning is perhaps related to a fear of losing a grip on rationality, and more importantly, on the supposed necessity of these concepts to underwrite normative statements and thus condition discourse.
% Richard Rorty describes this as follows:
% \begin{quote}
% The traditional view is that there is a core self which can look at, decide among, use, and express itself by means of, [\ldots] belief and desires.
% Further, these beliefs and desires are criticizable not simply by reference to their ability to cohere with one another, but by reference to something exterior to the network within which they are strands.
% Beliefs are, on this account, criticizable because they fail to correspond to reality.
% Desires are criticizable because they fail to correspond to the essential nature of the human self -- because they are ``irrational'' or ``unnatural''.
% \end{quote}
% Since the linguistic turn, language is seen as the medium that puts the self in contact with either reality or the nature of the self.
% Rationality is, in this picture, dependent on truth as its objective and logic as the means to attain it.
% The latter are embodied in language.
% The fear is thus that if we drop the picture of meaning as intimately tied to truth and logic, we lose the ground that rationality stands on, and thus lose the ability to make value judgments on sentences from a supposedly objective standpoint.
% Full-fledged relativism thus ensues.

\section{Signaling games and another problem of vagueness}
\label{sec:signaling-and-Lipman}

Signaling games were first introduced as models of communication by David Lewis~\parencite*{lewis_convention_1969}.
His original objective was to address an argument raised by W.~V.~Quine~\parencite*{quine_truth_1936} and others against the possibility of language having started as a conventional system: if language is a convention, it had to be originally established by an agreement; in order to establish an agreement, a convention-governed system of communication would have to already have been in place; thus, although some languages could have been established by agreement if another convention was already in place, not all of them could.
To this, Lewis retorts:
\begin{quote}
I offer this rejoinder: an agreement sufficient to create a convention need not be a transaction involving language or any other conventional activity.
All it takes is an exchange of manifestations of a propensity to conform to a regularity.%
~\parencite*[87--88]{lewis_convention_1969}
\end{quote}
In order to support this claim, Lewis studies coordination problems formalized in terms of game theory.
These are ``situations of interdependent decision by two or more agents in which coincidence of interest predominates and in which there are two or more proper coordination equilibria''~\parencite*[24]{lewis_convention_1969}.
In game theory terms, the agents interested in the coordination are the players, the game involves each player making an independent choice from his set of available actions, a payoff is what is attributed to each player based on the choices of both.
Adapting one of Lewis' examples, say Alice and Bob want to get together.
They usually meet at either Caf\'e One or Bistro Two.
Imagine there is no way for them to make any explicit agreement about it.
They are thus left to independently decide to either go to Caf\'e One or go to Bistro Two and hope for the other to show up there.
Neither has any preference for either place, but they do want to meet.
Each thus prefers to go to one of the places only if the other also decides to go to that particular place.

The setup of a coordination problem, \emph{i.e.}~the available actions and the relative interests of the players, can be represented in a payoff matrix, where rows show one player's available actions, columns the other player's available actions, and each cell gives the payoff for each of the players based on its row and column combination.
For example, consider the following matrix:
\begin{center}
\begin{tabular}{r|c|c|}
\multicolumn{1}{r}{}
 & \multicolumn{1}{c}{$b_1$}
 & \multicolumn{1}{c}{$b_2$} \\ \cline{2-3}
   $a_1$ & $1,1$ & $0,0$ \\ \cline{2-3}
   $a_2$ & $0,0$ & $1,1$ \\ \cline{2-3}
\end{tabular}
\end{center}
We can see this as representing the following game: one player has actions $A = \lbrace a_1, a_2 \rbrace$ available, the other $B = \lbrace b_1, b_2 \rbrace$; they prefer to coordinate $a_1$ with $b_1$ or $a_2$ with $b_2$, thus if this is achieved each gets a payoff of $1$, otherwise they each get $0$.
Connecting with the example laid out above, think of $a_1$ as Alice going to Caf\'e One, $a_2$ as Alice going to Bistro Two, $b_1$ as Bob going to Caf\'e One, and finally $b_2$ as Bob going to Bistro Two; their payoff is $1$ for both if they coordinate on the place to meet (independently of which one), and $0$ if they miscoordinate.
Formally, all we need to define in order to characterize such a situation are the sets of actions $A$ and $B$, and a utility function $U : A \times B \rightarrow \mathbb{R}^2$ that specifies the payoff for each player given the choices of actions.

The above example is a very simple case, but it serves to illustrate Lewis' notion of convention.
The two pairs of choices $(a_1,b_1)$ and $(a_2,b_2)$ are stable coordination equilibria, because in such a scenario no player has an incentive to unilaterally change his choice: if the first player is going to choose action $a_1$, the second player would get a payoff of $0$ for switching to $b_2$, instead of $1$ from sticking to $b_1$; the same reasoning applies, mutatis mutandis, to the other player and the other equilibrium.
However, neither player has a preference between those two pairs.
If the same coordination problem arises again, Lewis says, we can expect precedence to induce a kind of regularity: if the players manage to coordinate on one of the two equilibria, they should be expected to repeat the choices of actions that lead to that success, thus remaining in the same equilibrium.
Not only can we expect the players in such a repeated interaction to conform to a regularity, but also to expect others to do the same.
Their preference is to remain in a certain equilibrium given that others do too.
This summarizes Lewis's notion of a convention.

In order to extend this notion to \emph{linguistic} conventions, Lewis considers situations where the actions available involve sending and receiving signals or messages.
Thus, we could think of two players with different roles.
The first player, which Lewis calls the communicator~\parencite*[130]{lewis_convention_1969} and we will here call the sender, has knowledge about which of a number of possible states of affairs obtains and, depending on this information, chooses a signal to send.
The second player, which Lewis calls the audience~\parencite*[130]{lewis_convention_1969} and we will here call the receiver, has knowledge about which signal the sender chose and, based on this information, chooses one of several possible responses.
A preference relation exists between responses and states of affairs, and a payoff is attributed to each player based on the choices of both.
Note that Lewis assumes that no player has any preference regarding the particular signal that is used, provided that it enables coordination.
Formally, in order to describe the setup all we need is to specify a set of possible states of affairs $T$, a set of available signals or messages $M$, a set of responses or actions $A$, and the utility function $U : T \times A \rightarrow \mathbb{R}^2$.

Despite the added dimension of the signal exchange, these so-called signaling problems can be seen as particular cases of coordination problems if we consider the players' choices to be of contingency plans or strategies.
A communicator's contingency plan, or sender strategy as we will call it, is a specification of a choice of message for each possible state of affairs.
It thus describes the sender's behavior conditional on the state of affairs that obtains.
An audience's contingency plan, or receiver strategy as we will call it, analogously specifies a choice of action for each possible message.
Thus, formally, what the sender chooses is a function $\sigma : T \rightarrow M$ and the receiver a function $\rho : M \rightarrow A$.
The expected utility $EU$ of a pair of strategies $(\sigma,\rho)$ can be calculated using the utility function between states of affairs and actions as a sum of the payoffs for all cases. %, \emph{i.e.}:
% $$
% EU(\sigma, \rho) = \sum_{t \in T} U(t, \rho(\sigma(t)))
% $$
As an example, consider a game with $T = \lbrace t_1, t_2 \rbrace$, $M = \lbrace m_1, m_2 \rbrace$, $A = \lbrace a_1, a_2 \rbrace$, and the following utility matrix:
\begin{center}
\begin{tabular}{r|c|c|}
\multicolumn{1}{r}{}
 & \multicolumn{1}{c}{$a_1$}
 & \multicolumn{1}{c}{$a_2$} \\ \cline{2-3}
   $t_1$ & $1,1$ & $0,0$ \\ \cline{2-3}
   $t_2$ & $0,0$ & $1,1$ \\ \cline{2-3}
\end{tabular}
\end{center}
Possible sender and receiver strategies are, for example, $\sigma = \lbrace t_1 \mapsto m_2, t_2 \mapsto m_1 \rbrace$ and $\rho = \lbrace m_1 \mapsto a_2, m_2 \mapsto a_1 \rbrace$.
These would have an expected utility of $2$ for both sender and receiver, since when $t_1$ obtains the sender will use $m_2$ and to this message the receiver will respond with $a_1$ which achieves a payoff of $1$, when $t_2$ obtains the sender will use $m_1$ and to this message the receiver will respond with $a_2$ which also achieves a payoff of $1$.
% the following expected utility:
% \begin{equation}
% \begin{split}
% EU(\sigma, \rho) & = \sum_{t \in T} U(t, \rho(\sigma(t))) \\
%                  & = U(t_1, \rho(\sigma(t_1))) + U(t_2, \rho(\sigma(t_2))) \\
%                  & = U(t_1, \rho(m_2)) + U(t_2, \rho(m_1)) \\
%                  & = U(t_1, t_1) + U(t_2, t_1) \\
%                  & = (1,1) + (1,1) \\
%                  & = (2,2)
% \end{split}
% \end{equation}
% Based on this, we could also create a matrix of expected utilities for this example as follows:
% \begin{center}
% \begin{tabular}{r|c|c|c|c|}
% \multicolumn{1}{r}{}
%  & \multicolumn{1}{c}{$m_1 \mapsto a_1$}
%  & \multicolumn{1}{c}{$m_1 \mapsto a_1$}
%  & \multicolumn{1}{c}{$m_1 \mapsto a_2$}
%  & \multicolumn{1}{c}{$m_1 \mapsto a_2$} \\
% \multicolumn{1}{r}{}
%  & \multicolumn{1}{c}{$m_2 \mapsto a_1$}
%  & \multicolumn{1}{c}{$m_2 \mapsto a_2$}
%  & \multicolumn{1}{c}{$m_2 \mapsto a_1$}
%  & \multicolumn{1}{c}{$m_2 \mapsto a_2$} \\ \cline{2-5}
%    $t_1 \mapsto m_1, t_2 \mapsto m_1$ & $1,1$ & $1,1$ & $1,1$ & $1,1$ \\ \cline{2-5}
%    $t_1 \mapsto m_1, t_2 \mapsto m_2$ & $1,1$ & $2,2$ & $0,0$ & $1,1$ \\ \cline{2-5}
%    $t_1 \mapsto m_2, t_2 \mapsto m_1$ & $1,1$ & $0,0$ & $2,2$ & $1,1$ \\ \cline{2-5}
%    $t_1 \mapsto m_2, t_2 \mapsto m_2$ & $1,1$ & $1,1$ & $1,1$ & $1,1$ \\ \cline{2-5}
% \end{tabular}
% \end{center}
They also represent one of the two stable conventions in this game, the other being the pair of strategies $\sigma = \lbrace t_1 \mapsto m_1, t_2 \mapsto m_2 \rbrace$ and $\rho = \lbrace m_1 \mapsto a_1, m_2 \mapsto a_2 \rbrace$.
Conventions of this kind in a signaling problem are what Lewis calls \emph{signaling systems}.
An example of complete miscoordination would be $\sigma = \lbrace t_1 \mapsto m_1, t_2 \mapsto m_2 \rbrace$ and $\rho = \lbrace m_1 \mapsto a_2, m_2 \mapsto a_1 \rbrace$.
Partial coordination is achieved, for example, by $\sigma = \lbrace t_1 \mapsto m_1, t_2 \mapsto m_1 \rbrace$ and $\rho = \lbrace m_1 \mapsto a_1, m_2 \mapsto a_2 \rbrace$.

The approach adumbrated so far is not, nor does it attempt to be, a full-blown theory of meaning like one would have in the classical picture.
However, we can already see how it attempts to address the study of meaning from a very different angle.
There is a focus, not on meaning as a kind of correspondence, but rather on the use of signals for specific purposes.
There is also no appeal to truth as a guide for our inquiry.
In the examples discussed so far, agents are assumed to possess and exercise rationality.
It is not, however, the same rationality as we find in the classical picture, \emph{i.e.}~the willingness to abide by truth; it is rather a more pragmatic notion of rationality as utility maximization.
One advantage of such a paradigm shift is that we are no longer tied to the need to explain how language hooks on to the world; this question is no longer relevant on this account.
We can merely focus on trying to see how agents can use signals to cope with the world and achieve their purposes.
On the way, we will better understand meaning, not by trying to say what meaning is, but by trying to better understand how communication works.

Lewis signaling games can be seen as an alternative to the classical picture, even though the author himself might not have agreed with this use of his contribution.
In order to get there, some aspects of the approach need to be refined.
Brian Skyrms~\parencite*[80--104]{skyrms_evolution_1996} identifies some problems with the story so far.
Lewis' account of the stability of conventions rests on what could be considered strong demands for there to be a certain degree of required common knowledge between the players.
Namely, there needs to be a state of affairs that indicates to everyone involved that a certain regularity will hold, as well as ``mutual ascription of some common inductive standards and background information, rationality, mutual ascription of rationality, and so on''~\parencite*[56--57]{lewis_convention_1969}.
These requirements can seem excessive, even more so if we consider how simple signaling systems are when compared to human languages.
The models were introduced in order to help explain how language could get off the ground as a conventional system without any sort of prior agreement.
However, if we consider the origins of language from a historical perspective, it seems implausible to assume a high degree of rationality of the agents that started making use of primordial signaling systems which (hypothetically) evolved into languages.
Furthermore, communication through simple message exchange is something that almost all animals do: monkeys use calls, birds use singing, bees use dances, ants use pheromone trails, and so on.
A plausible account of the origin of language should first explain how signaling systems like those could get started, without assuming a great deal of rationality from the part of the agents involved.

In order to address this problem, Skyrms proposes we study signaling problems in evolutionary terms.
Rather than imagining, as Lewis does, rational agents making conscious decisions in possession of knowledge of the game and expectations of the behavior of other agents, we can imagine a simpler scenario inspired by biological evolution: there is a population of agents with biologically hardwired behaviors for engaging in interactions characteristic of a signaling problem; utility does not represent preference, but rather fitness for survival and reproduction; the make-up of the population evolves based on the relative fitness of the strategies represented in the population.
Such a setup attempts to capture the main features of natural selection: in a diverse population, agents with more successful strategies thrive, while agents with less fit strategies die off.
Although the inspiration for this scenario is biological evolution, similar things could be said~\parencite[\emph{e.g.}][]{dawkins_selfish_1978,boyd_culture_1985} about how ideas spread in a population of agents who can adopt or abandon them depending on how successful they prove to be.
The principles can be captured in a formal model that abstracts away from the interpretations: the replicator dynamics.
The only thing relevant to this equation are the relative proportions of strategies in a given population and the utility function.
Using it, one can compute which strategies evolve under which conditions.

Skyrms' evolutionary game theory approach to signaling games not only gives more plausible grounds to support Lewis' discussion of convention, but it also accomplishes an important conceptual change: it moves most of the theory and mathematical formalisms to the descriptive side of the investigation.
Utility represents how the modeler views the signaling problem and understands the relative advantages or disadvantages of different possible strategy combinations.
Dynamics describe how strategies can evolve when driven by mechanisms of utility maximization.
Focus is put on understanding how various ingredients to the model interact, and which results they produce, not on metaphysical concerns.
While the general framework manages to abstract quite some detail away from the formalization, it does leave room for them, especially when it comes to the dynamics.
We already mentioned the replicator equation that can be seen as representing biological or cultural evolution, but one can also use dynamics inspired by learning mechanisms, or even ones assuming a high degree of knowledge of the game and other players\todo{give examples and references?}.
This range of options goes hand in hand with assumptions of rationality, from nothing more than survival of the fittest in a biologically-inspired setting, to a certain degree of rationality in the case of dynamics that attempt to mimic mechanisms of iterative learning, to higher levels of rationality and even game-theoretical reasoning.
Each of these can be utilized depending on the problem that one is interested in characterizing.

The characterization of signaling problems in terms of evolutionary game theory allow us to explain why certain equilibria come to be and how.
Not only can we better understand why signaling systems are stable even without any assumptions of rationality, but we can also map out which initial conditions drive the system towards which equilibria and which don't\todo{mention something about phase portraits?}.
In a simple case like the example discussed above, an evolutionary process of the kind described always drives the population into a state where one signaling system takes over completely. %; which one of the possible two will depend on their relative proportions in the original population.
More complex signaling problems may have different evolutionary outcomes, sometimes unexpected ones.
Skyrms~\parencite*{skyrms_signals_2010} gives an overview of different topics studied using signaling games, including expansions of the framework itself (for example, considering other dynamics beyond the replicator equation), exploration of other factors that impact the evolution of signaling (for example, how agents are interconnected), or variations on the signaling problem and its basic assumptions (for example, loosening the alignment of interests in order to provide accounts of deceptive signal use).
Other uses of signaling games include discussions of categorization~\parencite[\emph{e.g.}][]{jager_language_2007}, compositionality~\parencite[\emph{e.g.}][]{barrett_evolution_2009}, incommensurability~\parencite[\emph{e.g.}][]{barrett_faithful_2010}, just to name a few\todo{more examples? less examples?}.
More recent overviews are given by \textcites{huttegger_how_2014} and \textcite{huttegger_dynamics_2014}.

So what about vagueness?
In the context of game-theoretic approaches to language, vagueness presents a new challenge.
Barton Lipman~\parencite*{lipman_why_2009} gives a detailed account of the problem.
Very succinctly, it can be put as follows.
In standard game-theoretic models of communication, vague usage of messages is less efficient than precise use.
Therefore, given that the dynamics (be it natural selection, cultural evolution, or rational choice) maximize utility, vagueness should be weeded out by these forces, giving rise to only precise languages.
However, vagueness is pervasive in our natural languages, and there is no reason to believe it is going away.
Lipman concludes then that ``we cannot explain the prevalence of vague terms in natural language without a model of bounded rationality which is significantly different from anything in the existing literature''~\parencite*[1]{lipman_why_2009}
In the following section we provide an overview of models that try to account for vagueness in a signaling games framework, and what the implications of each account are for how we view rationality.


% One interesting aspect of these signaling systems is that, if we were to observe the repeated interactions of sender and receiver according to those strategies from a bird's eye view, we would be inclined to say that the signals are meaningful.
% For example, if we consider the latter example, a sender would always send $m_1$ when state of affairs $t_1$ obtains to which the receiver would always respond with action $a_1$ which maximizes both players' payoff.
% It is as if $m_1$ means either ``$t_1$ obtains'' or ``do $a_1$''.
%


\section{Signaling models of vagueness}
\label{sec:vague-signaling}

Before we discuss the particular suggestions of how to account for vagueness in a signaling games framework, we need to discuss what useful changes could we make to the classic setup.
First, in order to work, the sorites paradox requires us to assume a relation between the vague term and a more precise underlying dimension (height for tallness, number of hairs for baldness, number of grains of sand for ``heapness'', and so on).
Not only does this property need to be much more fine-grained than the vague term, but it also needs to have some structure, in the sense that there is at least an order between the elements in it (thinking of height in centimeters, $180 > 179 > \ldots > 120$), but usually even a degree of how far apart these elements are from each other.
In terms of signaling games, we can take the height to be the state space and the terms the message space.
Because of the difference in granularity, we will typically be interested in cases where the state space is much larger than the message space.
For the structure of the state space, we can model this by defining a distance or similarity function between every element in the set, effectively making it a metric space.
Second, another important ingredient of the paradox is the acknowledgment of a certain degree of tolerance with respect to whether a certain term applies or not.
This tolerance decreases with distance: assuming a 180cm person is tall, one would easily tolerate the use of the term for a person measuring 179cm, less so for someone who is 170cm, and much less so for 160cm.
This can be modeled by using a utility function that is continuous rather than discrete and that is monotonously decreasing with distance in a metric space, \emph{i.e.}~success is not a matter of black and white, right or wrong, but a matter of degree, of how close the agent got to the optimal.

The simplest type of game to study in this scenario is one where the state space and the action space are the same.
We can imagine this as a game of guessing the state of affairs: the sender has knowledge of it, sends a message to the receiver, who in turn has to guess it; their payoff, as discussed above, is proportional to how close he got.
Other games are possible, depending on what situation of use we want to model.
For example, imagine I have two editions of a book, one of them is red the other one is green.
Wanting to read that book, I ask you to fetch the red book for me.
If you bring me a different red book, whose hue is very similar to my prototypical notion of red, I would still be disappointed.
If, however, you bring me my other edition of that book, despite it being far from red, I would be satisfied.
This example is just to illustrate that there is more to the use of vague terms in natural language than what the setup we just described can cover.
But, we believe, the setup captures one possible scenario where vagueness is relevant that would be difficult to capture in the classic formulations of signaling discussed before.

These games, called similarity-maximization or sim-max games for short, were first introduced by Gerhard J{\"a}ger and Robert van~Rooij~\parencite{jager_language_2007,Jager2007} and further studied by~\textcite{jager_voronoi_2011}.
What these authors find about this setup is that the evolutionary stable states are what they call Voronoi languages.
Roughly, these are situations where the sender uses messages in a way that can be seen as partitioning the state space into convex regions and the receiver responds with the central element of those regions.
For example, imagine a state space consisting of values of height in centimeters ranging from 40 to 280\footnote{Giving some slack to the values of the shortest and tallest people ever as recorded by Guinness World Records, respectively at 54.6 and 272.}.
Given two possible messages, the optimal sender strategy is to use one for all values from 40 up to 160, and the other for all values from 160 up to 280.
The optimal receiver strategy is to guess with 100 if given the first message and with 220 given the second message.
Confirming Lipman's argument, there is no vagueness in such an optimal language: when given a height of 159 the sender will always use one message and given a height of 161 will always use the other; correspondingly, the receiver's response is also crisp, associating only one guess with each message.

\begin{figure}
  \centering

  \begin{subfigure}[]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Rplot-example-strict.pdf}
    \caption{Crisp}
    \label{fig:example_stratsA}
  \end{subfigure}
  \hfill
  \begin{subfigure}[]{0.45\textwidth}
    \includegraphics[width=\textwidth]{Rplot-example-vague.pdf}
    \caption{Vague}
    \label{fig:example_stratsB}
  \end{subfigure}

  \caption{Example strategies for a state space with 50 states. Each line corresponds to a message. For the sender, it plots for each state the probability that the message is used. For the receiver, it plots for each state the probability that the response is that state, given the message.}
  \label{fig:example_strats}
\end{figure}

In an abstract setup, using 50 states uniformly distributed over the unit interval and two possible messages, such an optimal language looks like what we see in Figure~\ref{fig:example_stratsA}.
The sender/receiver strategy pairs that we are looking for look more like Figure~\ref{fig:example_stratsB}.
While in the former the probability that the sender uses one message decays sharply from 1 to 0, and increases sharply from 0 to 1 for the other message, at a given point, in the latter these transitions are smooth.
This means that, for some states in the middle of the state space, there is uncertainty as to which message will be used, whereas for states in the extremes this is almost certain.
Similarly for the receiver strategy, in the first example for each message there is an almost certain response, whereas in the second example this is a degree of uncertainty.

The interpretation of this uncertainty will be different depending on the interpretation of the model.
If we see it as an explanatory model of how two agents play the game, we can see it as randomization.
If we interpret the model as descriptive, it simply represents expected behavior in a manner agnostic to the underlying mechanisms.
A third option is to see probabilities as capturing relative numbers in a population of agents.
For example, if the sender strategy assigns a probability of $0.4$ of message $m$ being sent for state $t$, this would mean that $40\%$ of the population uses that message for that state, while $60\%$ uses the other.
This latter option leaves open the possible interpretation that each agent commands a crisp language and vagueness is only a population-level effect.
However, given the level of abstraction of the description so far, none of this is necessarily implied by the model.

Our question is thus what additional modifications to sim-max games are sufficient for the optimal languages to be more like Figure~\ref{fig:example_stratsB}, rather than like Figure~\ref{fig:example_stratsA}.
Let's look at some proposals in the literature.

\subsection{Bounded rationality}
\textcite{franke_vagueness_2011} make two suggestions of how vagueness in a signaling game can arise as a consequence of limitations in the cognitive capacities of rational agents.
The first proposal is called limited memory fictitious play and models agents playing a sim-max game where their ability to recall past interactions with others is limited to a certain number.
For a given interaction, each agent uses his limited memory of the other agent's past behavior to estimate the other's strategy.
Agents are assumed to be rational, thus each plays a best response (given the utility function) to their estimate of the other's strategy.
In order to observe the evolution of strategies in repeated interaction, this approach involves modeling several individual agents in actual play.
What the authors observe is the emergence of vague signaling at the level of the population, \emph{i.e.}~population averages of individual strategies exhibit the characteristics of a vague language as characterized before.
However, each agent still commands a crisp language, which is inadequate if the intention is to capture how vagueness presents itself in human languages.

In order to overcome this limitation, they make another proposal using the notion of a quantal response equilibrium.
The idea, inspired by experimental psychology, is to model the choice of best response as stochastic rather than deterministic, deviating from the optimal according to an exponentially decaying distribution (where small deviations are very likely, and large ones very rare).
The approach is not explanatory but descriptive: it is assumed that agents are not always able to make the absolute best choice, but the mechanism behind this limitation is left open to interpretation.
The degree to which agents deviate from the optimal behavior can be characterized by a parameter.
The authors find that for low values of this parameter, only babbling equilibria (where sender and receiver simply randomize, respectively, message and response uniformly) where no communication actually occurs.
Above a certain value of the parameter, other equilibria of the kind described in the beginning of this section arise, where agents communicate successfully, though not perfectly, using fuzzy strategies similar to the ones depicted in Figure~\ref{fig:example_stratsB}.


\subsection{Generalized reinforcement}
\parencite{oconnor_evolution_2014}

\subsection{Noisy perception}
\parencite{correia_bivalent_2013,franke_vagueness_2017}

\subsection{Preference misalignment}
\todo[inline]{Test CS~\parencite{crawford_strategic_1982} results in our model by using bias in utility function. READ Förster, M., and Riedel, F. (2011). Distorted Voronoi languages (working Paper). -> distorted Voronoi languages, i.e. shifted according to bias, but still crisp}

\subsection{Noisy communication}
\todo[inline]{Test if noise in communication channel as modeled by Blume~\parencite{blume_intentional_2014} induces vague strategies as well}


\printbibliography

\end{document}
